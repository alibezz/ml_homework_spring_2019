%This is my super simple Real Analysis Homework template

\documentclass[leqno]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[]{amsthm} %lets us use \begin{proof}
\usepackage{amsmath}
\usepackage[]{amssymb} %gives us the character \varnothing

\title{Homework 1}
\author{Aline Bessa -- N19183671}
\date\today
%This information doesn't actually show up on your document unless you use the maketitle command below

\begin{document}
\maketitle %This command prints the title based on information entered above

%Section and subsection automatically number unless you put the asterisk next to them.
\section*{Question 1}

\textbf{(a)} Let $L$ be a random variable that denotes the location where the rocks were collected, taking on values $\{A, B\}$. We then have that:

\begin{equation*}
P(L = B) = 4 \times P(L = A)
\end{equation*}
and
\begin{equation*}
P(L = A) + P(L = B) = 1 
\end{equation*}

\noindent Consequently, 

\begin{equation*}
\begin{split}
&P(L = A) + 4 \times P(L = A) = 1\\
&5 \times P(L = A) = 1\\
&P(L = A) = 0.2
\end{split}
\end{equation*}
and
\begin{equation*}
\begin{split}
&P(L = B) = 4 \times P(L = A) \\
&P(L = B) = 4 \times 0.2 \\
&P(L = B) = 0.8
\end{split}
\end{equation*}

\noindent \textbf{(b)} Let $w$ be a random variable that represents the weight of rocks. We then have to compute the \textit{posterior probability} that the rocks are from 
location A, i.e., $P(L = A| w_1 = 9.3, w_2 = 8.8, w_3 = 9.8)$, where $w_1, w_2$ and $w_3$ simply indicate 3 samples from $w$. Applying Bayes' theorem, we have that:

\begin{equation}
P(L = A| w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) = \frac{P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = A) \times P(L = A)}{P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8)}
\label{eq1}
\end{equation}

\noindent Assuming that the weights of the rocks ($w_1$, $w_2$, $w_3$) are conditionally independent, i.e., that the rock weights in a fixed location are independent,
we can rewrite the numerator in the right side of Equation \ref{eq1} as

\begin{equation*}
\begin{split}
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = A) \times P(L = A) = 
\\
&P(w_1 = 9.3 | L = A) \times P(w_2 = 8.8 | L = A) \times P(w_3 = 9.8| L = A) \times P(L = A)
\end{split}
\end{equation*}

\noindent Let us tackle this numerator first. Previously, we calculated that $P(L = A) = 0.2$. To compute the other factors, we use the probability density~\footnote{I used a scientific calculator to automate the calculation of pdfs throughout this document.} of the 
Gaussian distribution of rock weights in Location A, i.e., we use $\mu_1 = 9.2$ and $\sigma_1 = 1.6$.

\begin{equation*}
\begin{split}
P(w_1 = 9.3 | L = A) = P(w_1 = 9.3 | \mu_1 = 9.2, \sigma_1 = 1.6) = \frac{1}{\sqrt{2\pi(1.6)^2}}e^{-\frac{(9.3 - 9.2)^2}{2(1.6)^2}} \approx 0.249 
\\
P(w_1 = 8.8 | L = A) = P(w_1 = 8.8 | \mu_1 = 9.2, \sigma_1 = 1.6) = \frac{1}{\sqrt{2\pi(1.6)^2}}e^{-\frac{(8.8 - 9.2)^2}{2(1.6)^2}} \approx 0.242
\\
P(w_1 = 9.8 | L = A) = P(w_1 = 9.8 | \mu_1 = 9.2, \sigma_1 = 1.6) = \frac{1}{\sqrt{2\pi(1.6)^2}}e^{-\frac{(9.8 - 9.2)^2}{2(1.6)^2}} \approx 0.232
\end{split}
\end{equation*}
  
\noindent Combining these values with the prior, we have the following value for the numerator in Equation~\ref{eq1}:

\begin{equation*}
\begin{split}
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = A) \times P(L = A) \approx 0.249 \times 0.242 \times 0.232 \times 0.2
\\
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = A) \times P(L = A) \approx 0.00280
\end{split} 
\end{equation*}

\noindent As for the denominator in Equation~\ref{eq1}, it can be rewritten as the following marginal probability:

\begin{equation*}
\begin{split}
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) = 
\\
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = A) \times P(L = A) + 
\\
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = B) \times P(L = B) 
\end{split}
\end{equation*}

\noindent We already computed the parts of the denominator that concern $L = A$, so we just have to compute the terms that involve $L = B$. We
again also assume conditional independency and use the probability density of the 
Gaussian distribution of rock weights in Location B, i.e., we use $\mu_2 = 9.6$ and $\sigma_2 = 1.2$.

\begin{equation*}
\begin{split}
P(w_1 = 9.3 | L = B) = P(w_1 = 9.3 | \mu_2 = 9.6, \sigma_2 = 1.2) = \frac{1}{\sqrt{2\pi(1.2)^2}}e^{-\frac{(9.3 - 9.6)^2}{2(1.2)^2}} \approx 0.322 
\\
P(w_1 = 8.8 | L = B) = P(w_1 = 8.8 | \mu_2 = 9.6, \sigma_2 = 1.2) = \frac{1}{\sqrt{2\pi(1.2)^2}}e^{-\frac{(8.8 - 9.6)^2}{2(1.2)^2}} \approx 0.266
\\
P(w_1 = 9.8 | L = B) = P(w_1 = 9.8 | \mu_2 = 9.6, \sigma_2 = 1.2) = \frac{1}{\sqrt{2\pi(1.2)^2}}e^{-\frac{(9.8 - 9.6)^2}{2(1.2)^2}} \approx 0.328
\end{split}
\end{equation*}

\noindent Combining these terms with what was already computed for $L = A$, and with prior $P(L = B) = 0.8$, we can rewrite the denominator of Equation~\ref{eq1} as:

\begin{equation*}
\begin{split}
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) = P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = A) \times P(L = A) + 
\\
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = B) \times P(L = B)
\\
\\
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) \approx 0.00280 + P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = B) \times P(L = B)
\\
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) \approx 0.00280 +  (0.322 \times 0.266 \times 0.328 \times 0.8)
\\
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) \approx 0.00280 + 0.0225 
\\
&P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) \approx 0.0253
\end{split}
\end{equation*}

\noindent Combining the values computed for numerator and denominator, we have that
\begin{equation*}
\begin{split}
&P(L = A| w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) \approx \frac{0.00280}{0.0253}
\\
&P(L = A| w_1 = 9.3, w_2 = 8.8, w_3 = 9.8) \approx 0.111
\end{split}
\end{equation*}

\noindent This posterior probability indicates that, given the prior and the evidence, the probability that the rocks were collected in Location A is a little above 10\%.

\noindent \textbf{(c)} The ML hypothesis is the value $x$ of variable $L$, that maximizes $P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = x)$. Using the results in
\textbf{(b)}, we have that:

\begin{equation*}
P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = A) \approx 0.249 \times 0.242 \times 0.232 \approx 0.014
\end{equation*}
and

\begin{equation*}
P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = B) \approx 0.322 \times 0.266 \times 0.328 \approx 0.028
\end{equation*}

\noindent Given the weights of the rocks, the Gaussian distributions for $L = A$ and $L = B$, and ignoring the priors, we have that
the ML hypothesis is $L = B$ maximizes $P(w_1 = 9.3, w_2 = 8.8, w_3 = 9.8| L = x)$.

\section*{Question 2}

\noindent \textbf{(a)} Let $D$ be a random variable that indicates whether the person has the disease,
such that $D$ takes on values $\{+, -\}$. Moreover, let $R1$ be a variable that indicates the
result of method 1, and $R2$ be a variable that indicates the result of method 2. Both $R1$ and
$R2$ take on values $\{+, -\}$. Using a Bayesian approach, we have that, if a randomly selected
person tests positive with method 1, her probability of actually having the disease is
given by:

\begin{equation*}
P(D = +|R1 = +) = \frac{P(R1 = +|D = +) \times P(D = +)}{P(R1 = +)}
\end{equation*}  

\noindent The MAP hypothesis is the value $x$ that maximizes $P(R1 = +|D = x) \times P(D = x)$.
Note that $x$ is either $+$ or $-$. If $x = +$, i.e., if the person does have the disease,
we have that, given the information in the question,
\begin{equation*}
\begin{split}  
&P(D = +) = 0.0002
\\
&P(R1 = +|D = +) = 0.9
\\
&P(R1 = +|D = +) \times P(D = +) = 0.9 \times 0.0002 = 0.00018
\end{split}  
\end{equation*}

\noindent Note that $P(R1 = +|D = +)$ corresponds to $1 - 0.1$, where $0.1$ is the false negative
rate of method 1.

\noindent If $x = -$, that is, if the person does not have the disease, we have that
\begin{equation*}
\begin{split}  
&P(D = -) = 0.998
\\
&P(R1 = +|D = -) = 0.15
\\
&P(R1 = +|D = -) \times P(D = -) = 0.15 \times 0.998 = 0.1497
\end{split}  
\end{equation*}
\noindent Note that $P(R1 = +|D = -)$ is the false positive rate of method 1.

\noindent The MAP hypothesis then is $D = -$, i.e., it is more likely that the person does
not have the disease.

\hfill

\noindent \textbf{(b)} The ML hypothesis ignores the priors, so we just have to compare
$P(R1 = +|D = -)$ with $P(R1 = +|D = +)$. Given that $P(R1 = +|D = -) = 0.15$ and
$P(R1 = +|D = +)$ = 0.9, the ML hypothesis is $D = +$. In other words, if we do not consider
the rate of the disease as a prior, the conclusion changes: we believe that the person has
the disease if she tests positive with method 1.

\hfill

\noindent \textbf{(c)} Using a Bayesian approach, we want to compute the following
posterior probability:
\begin{equation*}
\begin{split}
&P(D = +| R1 = +, R2 = +) = \frac{P(R1 = +, R2 = +| D = +) \times P(D = +)}{P(R1 = +, R2 = +)}
\end{split}  
\end{equation*}  
As the results of the methods are independent, we have that
\begin{equation}
\begin{split}
&P(D = +| R1 = +, R2 = +) = \frac{P(R1 = +|D = +) \times P(R2 = +| D = +) \times P(D = +)}{P(R1 = +, R2 = +)}
\end{split}
\label{eq2}
\end{equation}  

\noindent Let us calculate the numerator in the right side of Equation~\ref{eq2} first. From
the data in the question, we have that
\begin{equation*}
\begin{split}
&P(R1 = +, R2 = +| D = +) \times P(D = +) = P(R1 = +|D = +) \times P(R2 = +| D = +) \times P(D = +)
\\
&P(R1 = +, R2 = +| D = +) \times P(D = +) = 0.9 \times 0.97 \times 0.0002
\\
&P(R1 = +, R2 = +| D = +) \times P(D = +) = 0.0001746
\end{split}  
\end{equation*}  
Note that $P(R2 = +| D = +) = 0.97$ because the false negative rate of method 2 is 3\%. Now, let us
compute the denominator of Equation~\ref{eq2}, which corresponds to the following marginal
probability:
\begin{equation*}
\begin{split}
&P(R1 = +, R2 = +) = [(P(R1 = +|D = +) \times P(D = +)) + (P(R1 = +|D = -) \times P(D = -))] \times
\\
&[(P(R2 = +|D = +) \times P(D = +)) + (P(R2 = +|D = -) \times P(D = -))]
\\
\\
&P(R1 = +, R2 = +) = [(0.9 \times 0.0002) + (0.15 \times 0.998)] \times [(0.97 \times 0.0002) + (0.05 \times 0.998)]
\\
&P(R1 = +, R2 = +) = [0.00018 + 0.1497] \times [0.000194 + 0.0499]
\\
&P(R1 = +, R2 = +) = 0.14988 \times 0.050094
\\
&P(R1 = +, R2 = +) = 0.007508089
\end{split}  
\end{equation*}
By combining the numerator and the denominator, we have that
\begin{equation*}
\begin{split}
&P(D = +| R1 = +, R2 = +) = \frac{0.0001746}{0.007508089}
\\
&P(D = +| R1 = +, R2 = +) \approx 0.0233
\end{split}  
\end{equation*}
Given this posterior probability, we conclude that even if the person tests positive for both methods, the probability of having the
disease is still very low: a bit above 2\%. \textbf{CHECK THE CALCULATIONS (AND THE MARGINAL FORMAT)!}

\section*{Question 3}

\noindent \textbf{(a)} Assuming that the coin tosses are independent, \textbf{CAN I ASSUME THIS INDEPENDENCY?}
we have that
\begin{equation*}
\begin{split}
&P(TTHTTH|\theta) = P(T|\theta) \times P(T|\theta) \times P(H|\theta) \times P(T|\theta) \times P(T|\theta) \times P(H|\theta)
\\
&P(TTHTTH|\theta) = (1 - \theta) \times (1 - \theta) \times \theta \times (1 - \theta) \times (1 - \theta) \times \theta
\\
&P(TTHTTH|\theta) = (1 - \theta)^4 \times \theta^2
\end{split}  
\end{equation*}

\hfill

\noindent \textbf{(b)} Given the result calculated in \textbf{(a)}, we have that
\begin{equation*}
\begin{split}
&\log P(TTHTTH|\theta) = \log ((1 - \theta)^4 \times \theta^2)
\\
&\log P(TTHTTH|\theta) = \log ((1 - \theta)^4) + \log (\theta^2)
\\
&\log P(TTHTTH|\theta) = 4 \times \log (1 - \theta) + 2 \times \log (\theta)
\end{split}  
\end{equation*}

\noindent That is, if the answer has to be in the form $a \times \log (\theta) + b \times \log (1 - \theta)$, $a = 2$ and $b = 4$.

\hfill 

\noindent \textbf{(c)} The value $\theta$ that maximizes $argmax_{\theta}P(TTHTTH|\theta)$ is the same that maximizes $argmax_{\theta}\log P(TTHTTH|\theta)$, 
 because $\log$ is a monotone transformation that preserves the location of maximum (and minimum) values. To find it, we just need to take 
 the derivative of $\log P(TTHTTH|\theta)$ with respect to $\theta$ and calculate the critical points. Without loss of generality, let $\log = \ln$. We then have that:
\begin{equation*}
\begin{split}
&\frac{d}{d\theta}\ln P(TTHTTH|\theta) = \frac{d}{d\theta}[4 \times \ln (1 - \theta) + 2 \times \ln (\theta)]
\\
&\frac{d}{d\theta}\ln P(TTHTTH|\theta) = \frac{4}{1 - \theta} \times -1 + \frac{2}{\theta}
\\
&\frac{d}{d\theta}\ln P(TTHTTH|\theta) = \frac{-4}{1 - \theta} + \frac{2}{\theta}
\end{split}  
\end{equation*} 

\noindent The critical point is the value of $\theta$ that makes $\frac{d}{d\theta}\ln P(TTHTTH|\theta) = 0$, that is
\begin{equation*}
\begin{split}
&\frac{-4}{1 - \theta} + \frac{2}{\theta} = 0
\\
&-4 \times \theta + 2 \times (1 - \theta) = 0
\\
&-4 \times \theta + 2 - 2 \times \theta = 0
\\
&-6 \times \theta + 2 = 0
\\
&-6 \times \theta = -2
\\
& \theta = \frac{1}{3}
\end{split}  
\end{equation*} 

\noindent The \textit{maximum likelihood estimate} of $\theta$ given the results of the coin tosses is $\theta = \frac{1}{3}$.
\end{document}
